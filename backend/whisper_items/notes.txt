line 11: model = WhisperModel(model_size, device="cpu", compute_type="int8")
on certain machines with nvidia GPU's  setting device to "cuda" and compute_type to "float16" 
may significantly improve runtimes if the device is compatible

env var:
in terminal, you may need to set environment variable 
KMP_DUPLICATE_LIB_OK to true via 
set KMP_DUPLICATE_LIB_OK=True
or
export KMP_DUPLICATE_LIB_OK=True 
